{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if (!(\"Notification\" in window)) {\n",
       "    alert(\"This browser does not support desktop notifications, so the %%notify magic will not work.\");\n",
       "} else if (Notification.permission !== 'granted' && Notification.permission !== 'denied') {\n",
       "    Notification.requestPermission(function (permission) {\n",
       "        if(!('permission' in Notification)) {\n",
       "            Notification.permission = permission;\n",
       "        }\n",
       "    })\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn\n",
    "import json\n",
    "import jupyternotify\n",
    "ip = get_ipython()\n",
    "ip.register_magics(jupyternotify.JupyterNotifyMagics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./hidden_units.json') as file:\n",
    "    hidden_units = json.load(file)\n",
    "\n",
    "CORRCOEF_THRESHOLD = 0.5\n",
    "NUM_STEPS = 10000\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "# Número de hidden layers: 1, 2, 5, 10, 20, 30\n",
    "hidden_units = hidden_units[31] #Número de hidden units por hidden layer, cada posição do vetor é um layer diferente\n",
    "activation_fn = tf.nn.leaky_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(x, y, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(x), y))\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "def input_fn_test(x, y, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(x), y))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "def classifier_fn(feature_columns, hidden_units, activation_fn, BATCH_SIZE, NUM_STEPS):  \n",
    "    classifier = tf.estimator.DNNClassifier(\n",
    "        feature_columns=feature_columns,\n",
    "        hidden_units=hidden_units, #1 hidden layer com 1000 hidden units\n",
    "        n_classes=23, #Pode distinguir até 23 valores diferentes\n",
    "        activation_fn=activation_fn,\n",
    "        batch_norm=False)\n",
    "\n",
    "    # Treino\n",
    "    classifier.train(\n",
    "        input_fn=lambda:input_fn(x_train, y_train, BATCH_SIZE),\n",
    "        steps=NUM_STEPS)\n",
    "\n",
    "    # Teste\n",
    "    eval_result = classifier.evaluate(\n",
    "        input_fn=lambda:input_fn_test(x_test, y_test, BATCH_SIZE))\n",
    "\n",
    "    #Abre arquivo e adiciona no fim\n",
    "    file = open(\"./output.csv\", \"a\")\n",
    "    file.write(f'\"{len(hidden_units)}\",\"{hidden_units}\",\"{eval_result[\"accuracy\"]}\",\"{eval_result[\"average_loss\"]}\",\"{eval_result[\"loss\"]}\",\"leaky_relu\"\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
    "                \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\",\n",
    "                \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\",\n",
    "                \"dst_host_count\", \"dst_host_srv_count\", \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
    "                \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"attack\"]\n",
    "\n",
    "dataset = pd.read_csv('../../dataset/kddcup.data_10_percent_corrected', header=None, names=column_names)\n",
    "\n",
    "protocol_type = {\"icmp\": 0, \"tcp\": 1, \"udp\": 2}\n",
    "service = {\"auth\": 0, \"bgp\": 1, \"courier\": 2, \"csnet_ns\": 3, \"ctf\": 4, \"daytime\": 5, \"discard\": 6, \"domain\": 7, \"domain_u\": 8, \"echo\": 9, \"eco_i\": 10, \"ecr_i\": 11, \"efs\": 12,\n",
    "           \"exec\": 13, \"finger\": 14, \"ftp\": 15, \"ftp_data\": 16, \"gopher\": 17, \"hostnames\": 18, \"http\": 19, \"http_443\": 20, \"imap4\": 21, \"IRC\": 22, \"iso_tsap\": 23, \"klogin\": 24,\n",
    "           \"kshell\": 25, \"ldap\": 26, \"link\": 27, \"login\": 28, \"mtp\": 29, \"name\": 30, \"netbios_dgm\": 31, \"netbios_ns\": 32, \"netbios_ssn\": 33, \"netstat\": 34, \"nnsp\": 35, \"nntp\": 36,\n",
    "           \"ntp_u\": 37, \"other\": 38, \"pm_dump\": 39, \"pop_2\": 40, \"pop_3\": 41, \"printer\": 42, \"private\": 43, \"red_i\": 44, \"remote_job\": 45, \"rje\": 46, \"shell\": 47, \"smtp\": 48,\n",
    "           \"sql_net\": 49, \"ssh\": 50, \"sunrpc\": 51, \"supdup\": 52, \"systat\": 53, \"telnet\": 54, \"tftp_u\": 55, \"time\": 56, \"tim_i\": 57, \"urh_i\": 58, \"urp_i\": 59, \"uucp\": 60,\n",
    "           \"uucp_path\": 61, \"vmnet\": 62, \"whois\": 63, \"X11\": 64, \"Z39_50\": 65}\n",
    "flag = {\"OTH\": 0, \"REJ\": 1, \"RSTO\": 2, \"RSTOS0\": 3, \"RSTR\": 4, \"S0\": 5, \"S1\": 6, \"S2\": 7, \"S3\": 8, \"SF\": 9, \"SH\": 10}\n",
    "attack = {\"back.\": 0, \"buffer_overflow.\": 1, \"ftp_write.\": 2, \"guess_passwd.\": 3, \"imap.\": 4, \"ipsweep.\": 5, \"land.\": 6, \"loadmodule.\": 7, \"multihop.\": 8, \"neptune.\": 9,\n",
    "          \"nmap.\": 10, \"normal.\": 11, \"perl.\": 12, \"phf.\": 13, \"pod.\": 14, \"portsweep.\": 15, \"rootkit.\": 16, \"satan.\": 17, \"smurf.\": 18, \"spy.\": 19, \"teardrop.\": 20,\n",
    "          \"warezclient.\": 21, \"warezmaster.\": 22}\n",
    "\n",
    "#Troca os valores de string para número\n",
    "dataset = dataset.replace({\"protocol_type\": protocol_type, \"service\": service, \"flag\": flag, \"attack\": attack})\n",
    "\n",
    "#Coloca todas em columas de feature em x e a de resultado em y\n",
    "x, y = dataset, dataset.pop(\"attack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\numpy\\lib\\function_base.py:3183: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\python\\python36\\lib\\site-packages\\numpy\\lib\\function_base.py:3184: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "included_features = column_names\n",
    "included_features.remove(\"attack\")\n",
    "\n",
    "\n",
    "i = 0\n",
    "j = 1\n",
    "while i < len(included_features):\n",
    "    col1 = dataset[column_names[i]]\n",
    "\n",
    "    while j < len(included_features):\n",
    "        col2 = dataset[column_names[j]]\n",
    "        corrcoef = np.corrcoef(col1, col2)\n",
    "\n",
    "        if abs(corrcoef[0][1]) > CORRCOEF_THRESHOLD:\n",
    "            included_features.remove(included_features[j])\n",
    "        else:\n",
    "            j = j + 1\n",
    "\n",
    "    i = i + 1\n",
    "    j = i + 1\n",
    "\n",
    "for feature in included_features: #Por algum motivo o pop dentro do while não funcionava\n",
    "    x.pop(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Everton\\AppData\\Local\\Temp\\tmp_4ggvp3n\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "$(document).ready(\n",
       "    function() {\n",
       "        function appendUniqueDiv(){\n",
       "            // append a div with our uuid so we can check that it's already\n",
       "            // been sent and avoid duplicates on page reload\n",
       "            var notifiedDiv = document.createElement(\"div\")\n",
       "            notifiedDiv.id = \"598b5338-8249-4a01-9610-6d534f706e67\"\n",
       "            element.append(notifiedDiv)\n",
       "        }\n",
       "\n",
       "        // only send notifications if the pageload is complete; this will\n",
       "        // help stop extra notifications when a saved notebook is loaded,\n",
       "        // which during testing gives us state \"interactive\", not \"complete\"\n",
       "        if (document.readyState === 'complete') {\n",
       "            // check for the div that signifies that the notification\n",
       "            // was already sent\n",
       "            if (document.getElementById(\"598b5338-8249-4a01-9610-6d534f706e67\") === null) {\n",
       "                var notificationPayload = {\"requireInteraction\": false, \"icon\": \"/static/base/images/favicon.ico\", \"body\": \"Done!\"};\n",
       "                if (Notification.permission !== 'denied') {\n",
       "                    if (Notification.permission !== 'granted') { \n",
       "                        Notification.requestPermission(function (permission) {\n",
       "                            if(!('permission' in Notification)) {\n",
       "                                Notification.permission = permission\n",
       "                            }\n",
       "                        })\n",
       "                    }\n",
       "                    if (Notification.permission === 'granted') {\n",
       "                    var notification = new Notification(\"Jupyter Notebook\", notificationPayload)\n",
       "                    appendUniqueDiv()\n",
       "                    notification.onclick = function () {\n",
       "                        window.focus();\n",
       "                        this.close();\n",
       "                        };\n",
       "                    } \n",
       "                }     \n",
       "            }\n",
       "        }\n",
       "    }\n",
       ")\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.logging.set_verbosity(tf.logging.WARN)\n",
    "\n",
    "n_train = math.ceil(len(x.index)*0.9)\n",
    "n_test = len(x.index) - n_train\n",
    "\n",
    "x_train = x[:n_train]\n",
    "y_train = y[:n_train]\n",
    "\n",
    "x_test = x[n_train:n_train+n_test]\n",
    "y_test = y[n_train:n_train+n_test]\n",
    "\n",
    "feature_columns = []\n",
    "for feature in x_train.keys():\n",
    "    feature_columns.append(tf.feature_column.numeric_column(key=feature))\n",
    "\n",
    "classifier_fn(feature_columns, hidden_units, activation_fn, BATCH_SIZE, NUM_STEPS)\n",
    "\n",
    "%notify -m \"Done!\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

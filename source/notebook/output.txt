###
Hidden layers: 1
Hidden units: [10]
Activation fn: <function relu at 0x0000014FFCB5DE18>
Accuracy: 0.9675924181938171
###
###
Hidden layers: 2
Hidden units: [10, 10]
Activation fn: <function relu at 0x000001F578063E18>
Accuracy: 0.9864377975463867
###
###
Hidden layers: 5
Hidden units: [10, 10, 10, 10, 10]
Activation fn: <function relu at 0x0000024810CB5E18>
Accuracy: 0.980021059513092
###
###
Hidden layers: 10
Hidden units: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10]
Activation fn: <function relu at 0x00000200EF3BFE18>
Accuracy: 0.9083640575408936
###
###
Hidden layers: 20
Hidden units: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]
Activation fn: <function relu at 0x000002325EC06E18>
Accuracy: 0.9863973259925842
###
###
Hidden layers: 30
Hidden units: [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10]
Activation fn: <function relu at 0x000001F98A8EFE18>
Accuracy: 0.17851504683494568
###
###
Hidden layers: 1
Hidden units: [20]
Activation fn: <function relu at 0x0000014DAF074E18>
Accuracy: 0.985830545425415
###
###
Hidden layers: 2
Hidden units: [20, 20]
Activation fn: <function relu at 0x000001479EBADE18>
Accuracy: 0.9912351965904236
###
###
Hidden layers: 5
Hidden units: [20, 20, 20, 20, 20]
Activation fn: <function relu at 0x000002540B1A5E18>
Accuracy: 0.9723088145256042
###
###
Hidden layers: 10
Hidden units: [20, 20, 20, 20, 20, 20, 20, 20, 20, 20]
Activation fn: <function relu at 0x0000026CC5189E18>
Accuracy: 0.9609125256538391
###
###
Hidden layers: 20
Hidden units: [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]
Activation fn: <function relu at 0x000002B5591F6E18>
Accuracy: 0.9642929434776306
###
###
Hidden layers: 30
Hidden units: [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]
Activation fn: <function relu at 0x00000227134DBE18>
Accuracy: 0.9868223667144775
###
###
Hidden layers: 1
Hidden units: [50]
Activation fn: <function relu at 0x00000209BCBBCE18>
Accuracy: 0.6315736174583435
###
###
Hidden layers: 2
Hidden units: [50, 50]
Activation fn: <function relu at 0x000001DF4690EE18>
Accuracy: 0.9777742028236389
###
###
Hidden layers: 5
Hidden units: [50, 50, 50, 50, 50]
Activation fn: <function relu at 0x00000215047EFE18>
Accuracy: 0.9893931150436401
###
###
Hidden layers: 10
Hidden units: [50, 50, 50, 50, 50, 50, 50, 50, 50, 50]
Activation fn: <function relu at 0x000001C7B68D4E18>
Accuracy: 0.9852030277252197
###
###
Hidden layers: 20
Hidden units: [50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]
Activation fn: <function relu at 0x0000020FC3CEFE18>
Accuracy: 0.9859519600868225
###
###
Hidden layers: 30
Hidden units: [50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50]
Activation fn: <function relu at 0x0000027070EEAE18>
Accuracy: 0.9836443662643433
###
###
Hidden layers: 20
Hidden units: [100, 95, 90, 85, 80, 75, 70, 65, 60, 55, 50, 45, 40, 35, 30, 25, 20, 15, 10, 5]
Activation fn: <function relu at 0x0000015C68F85E18>
Accuracy: 0.985324501991272
###
###
Hidden layers: 20
Hidden units: [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 90, 95, 100]
Activation fn: <function relu at 0x0000018B332EBE18>
Accuracy: 0.982935905456543
###
###
Hidden layers: 10
Hidden units: [100, 90, 80, 70, 60, 50, 40, 30, 20, 10]
Activation fn: <function relu at 0x000002DA854ADE18>
Accuracy: 0.9823083877563477
###
###
Hidden layers: 10
Hidden units: [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]
Activation fn: <function relu at 0x000002240E255E18>
Accuracy: 0.9020282626152039
###
###
Hidden layers: 5
Hidden units: [100, 80, 60, 40, 20]
Activation fn: <function relu at 0x0000020255F0EE18>
Accuracy: 0.9912958741188049
###
###
Hidden layers: 5
Hidden units: [20, 40, 60, 80, 100]
Activation fn: <function relu at 0x000001679B179E18>
Accuracy: 0.99295574426651
###

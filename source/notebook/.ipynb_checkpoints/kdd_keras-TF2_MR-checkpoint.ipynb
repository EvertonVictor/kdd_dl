{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kdd_keras-TF2_MR - Revisão\n",
    "9 de Dezembro, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neste primeiro bloco é realizada a importação das bibliotecas utilizadas no código.\n",
    "- **matplotlib**: Utilizada para impressão dos gráficos dos resultados dos modelos\n",
    "- **pandas**: Utilizada para manipulação do conjunto de dados\n",
    "- **numpy**: Utilizada para operação matemáticas em cima do conjunto de dados\n",
    "- **keras**: Utilizada para criação da rede neural\n",
    "- **time**: Utilizada para marcar o tempo de execução do código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T18:29:10.834946Z",
     "start_time": "2020-12-09T18:29:06.451408Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T18:29:10.839401Z",
     "start_time": "2020-12-09T18:29:10.836726Z"
    }
   },
   "outputs": [],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas as configurações referentes a rede neural estão no bloco abaixo. Aqui é possível escolher qual conjunto de dados será utilizado, se o código deverá ou não remover as colunas correlacionadas, como será a divisão de dados entre treino e teste, a função de ativação utilizada e a taxa de aprendizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T18:58:19.257200Z",
     "start_time": "2020-12-09T18:58:19.249296Z"
    }
   },
   "outputs": [],
   "source": [
    "# Flag para remoção das colunas correlacionadas.\n",
    "CLEAN_DATASET = True\n",
    "\n",
    "# Flag para decisão de qual versão do dataset usar\n",
    "DATASET_COMPLETO = False\n",
    "\n",
    "# Caminho para o dataset\n",
    "# Endereço para download: http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "# Backup: http://web.archive.org/web/*/http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n",
    "if DATASET_COMPLETO:\n",
    "    DATASET_PATH = \"D:/UNIFEI/TCC/kdd_dl/dataset/kddcup.data.corrected\" \n",
    "    # Treino 98%, Validação 1%, Teste 1%\n",
    "    # https://stackoverflow.com/a/13613316\n",
    "    TRAIN_PERCENTAGE = 0.98\n",
    "    VALIDATION_PERCENTAGE = 0.01\n",
    "    TEST_PERCENTAGE = 0.01\n",
    "else:\n",
    "    DATASET_PATH = \"D:/UNIFEI/TCC/kdd_dl/dataset/kddcup.data_10_percent_corrected\"\n",
    "    # Treino 80%, Validação 8%, Teste 20%\n",
    "    TRAIN_PERCENTAGE = 0.8\n",
    "    VALIDATION_PERCENTAGE = 0.1 # A porcentagem de validação é sobre os dados de Treino (no caso vais ser 0.8%\n",
    "    TEST_PERCENTAGE = 0.2\n",
    "    \n",
    "## Threshold de correlação para exclusão das colunas do dataset\n",
    "CORRCOEF_THRESHOLD = 0.5\n",
    "\n",
    "## Ignora os warnings de divisão por NaN\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "\n",
    "EPOCHS = 32 # Quantas vezes os dados serão corridos completamente\n",
    "BATCH_SIZE = 1024 # Quantas linhas do dataset serão lidas por vez\n",
    "SHUFFLE = True # Mistura os dados antes do treino\n",
    "VERBOSE = 1 # 0 - Desativa os logs durante o treino, 1 - Imprime os logs durante o treino\n",
    "LEARNING_RATE = 0.01 # Taxa de aprendizado\n",
    "ACTIVATION_FN = \"relu\" # Função de ativação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O bloco abaixo realiza a leitura do conjunto de dados e cria um *dataframe* do *pandas* para manipulação mais fácil dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T18:58:28.739334Z",
     "start_time": "2020-12-09T18:58:27.272228Z"
    }
   },
   "outputs": [],
   "source": [
    "# Nome das colunas do dataset\n",
    "column_names = [\n",
    "    \"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\",\n",
    "    \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
    "    \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\",\n",
    "    \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\", \"is_guest_login\",\n",
    "    \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\",\n",
    "    \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\", \"dst_host_count\", \"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\", \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"attack\",\n",
    "]\n",
    "\n",
    "#Leitura do dataset\n",
    "dataset = pd.read_csv(\n",
    "    DATASET_PATH,\n",
    "    header = None,\n",
    "    names = column_names)\n",
    "dataset.shape # sempre é bom verificar o shape do dataset ao se criar o dataframe: (494021, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T18:58:32.127538Z",
     "start_time": "2020-12-09T18:58:32.104511Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Features:** 41 variáveis dependentes (\"X\")\n",
    "- **Target:** 1 variável indeoendente (\"y\") ==> dataset['attack']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T18:58:38.445383Z",
     "start_time": "2020-12-09T18:58:38.310458Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como o conjunto de dados possui valores léxicos, é necessário trocá-los por valores numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T18:58:46.826199Z",
     "start_time": "2020-12-09T18:58:46.757637Z"
    }
   },
   "outputs": [],
   "source": [
    "#Pega os valores  únicos das colunas que tem string\n",
    "protocol_type_values = dataset.protocol_type.unique()\n",
    "service_values = dataset.service.unique()\n",
    "flag_values = dataset.flag.unique()\n",
    "attack_values = dataset.attack.unique()\n",
    "\n",
    "#Transforma as strings em números\n",
    "protocol_type_dict = dict(zip(protocol_type_values, range(len(protocol_type_values))))\n",
    "service_dict = dict(zip(service_values, range(len(service_values))))\n",
    "flag_dict = dict(zip(flag_values, range(len(flag_values))))\n",
    "attack_dict = dict(zip(attack_values, range(len(attack_values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T18:58:49.951858Z",
     "start_time": "2020-12-09T18:58:49.947538Z"
    }
   },
   "outputs": [],
   "source": [
    "protocol_type_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T18:58:51.271675Z",
     "start_time": "2020-12-09T18:58:51.265617Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "service_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T18:58:52.355392Z",
     "start_time": "2020-12-09T18:58:52.351471Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "flag_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T18:58:53.430982Z",
     "start_time": "2020-12-09T18:58:53.426206Z"
    }
   },
   "outputs": [],
   "source": [
    "attack_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T21:26:59.557151Z",
     "start_time": "2020-12-09T21:26:59.427796Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.attack.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T18:29:12.382649Z",
     "start_time": "2020-12-09T18:29:12.380643Z"
    }
   },
   "outputs": [],
   "source": [
    "#Substitui os valores no dataset que são string por números\n",
    "# dataset = dataset.replace(\n",
    "#     {\"protocol_type\": protocol_type_dict,\n",
    "#      \"service\": service_dict,\n",
    "#      \"flag\": flag_dict,\n",
    "#      \"attack\": attack_dict}\n",
    "# )\n",
    "# dataset = dataset.replace({\"attack\": attack_dict})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpeza do dataset (colunas numericas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T18:59:04.573982Z",
     "start_time": "2020-12-09T18:59:04.569506Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pego as colunas numéricas\n",
    "numeric_cols = dataset._get_numeric_data().columns\n",
    "print(numeric_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T18:59:14.462591Z",
     "start_time": "2020-12-09T18:59:14.458518Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T18:59:39.542781Z",
     "start_time": "2020-12-09T18:59:35.907619Z"
    }
   },
   "outputs": [],
   "source": [
    "#Apaga as colunas que tem correlação entre elas que seja maior que CORRCOEF_THRESHOLD\n",
    "num_col_in = dataset.shape[1]\n",
    "if CLEAN_DATASET:\n",
    "    excluded = list()\n",
    "    \n",
    "    for index_1 in range(len(numeric_cols)):\n",
    "        for index_2 in range(len(numeric_cols)):\n",
    "            if numeric_cols[index_1] not in excluded and numeric_cols[index_1] in numeric_cols and numeric_cols[index_2] not in excluded and index_1 != index_2:\n",
    "                corrcoef = np.corrcoef(dataset[numeric_cols[index_1]], dataset[numeric_cols[index_2]])\n",
    "\n",
    "                if abs(corrcoef[0][1]) > CORRCOEF_THRESHOLD:\n",
    "                    excluded.append(numeric_cols[index_2])\n",
    "                \n",
    "    dataset = dataset[dataset.columns.difference(excluded)]\n",
    "num_col_out = dataset.shape[1]\n",
    "print(f\"Colunas suprimidas {num_col_in - num_col_out} colunas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:00:20.537810Z",
     "start_time": "2020-12-09T19:00:20.184314Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.describe().T # mostra dados estatísticos das colunas numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:01:15.662585Z",
     "start_time": "2020-12-09T19:01:15.658928Z"
    }
   },
   "outputs": [],
   "source": [
    "# Pego as colunas categoricas\n",
    "categorical_cols = list(set(dataset.columns)-set(numeric_cols))\n",
    "print(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:01:26.511653Z",
     "start_time": "2020-12-09T19:01:26.458080Z"
    }
   },
   "outputs": [],
   "source": [
    "#Normalizo só as numéricas\n",
    "names_to_normalize = list(dataset.drop(categorical_cols, axis=1).columns)\n",
    "print(names_to_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:02:00.223247Z",
     "start_time": "2020-12-09T19:02:00.219193Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:02:25.508304Z",
     "start_time": "2020-12-09T19:02:25.505114Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(names_to_normalize)) # 25 total - 4 categoricos = 21 numericos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:02:31.567371Z",
     "start_time": "2020-12-09T19:02:29.670762Z"
    }
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "data_scaled = dataset.copy(deep=True)\n",
    "data_scaled[names_to_normalize] = min_max_scaler.fit_transform(\n",
    "    dataset[names_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:02:38.904909Z",
     "start_time": "2020-12-09T19:02:38.871760Z"
    }
   },
   "outputs": [],
   "source": [
    "data_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:02:51.779306Z",
     "start_time": "2020-12-09T19:02:51.088271Z"
    }
   },
   "outputs": [],
   "source": [
    "data_scaled.describe().T # mostra dados estatísticos das colunas numéricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limpeza do dataset (colunas alfanuméricas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:05:34.068531Z",
     "start_time": "2020-12-09T19:05:32.623376Z"
    }
   },
   "outputs": [],
   "source": [
    "# Substitui os valores no dataset que são string por números\n",
    "data_scaled = data_scaled.replace({\n",
    "    \"protocol_type\": protocol_type_dict,\n",
    "    \"service\": service_dict,\n",
    "    \"flag\": flag_dict,\n",
    "    \"attack\": attack_dict\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:05:35.766770Z",
     "start_time": "2020-12-09T19:05:35.741816Z"
    }
   },
   "outputs": [],
   "source": [
    "data_scaled.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:05:41.817825Z",
     "start_time": "2020-12-09T19:05:41.813332Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html\n",
    "def apply_dummies(df, feature):\n",
    "    get_dummies = pd.get_dummies(df[feature])\n",
    "    for x in get_dummies.columns:\n",
    "        dummy_name = f\"{feature}-{x}\"\n",
    "        df[dummy_name] = get_dummies[x]\n",
    "    df.drop(feature, axis=1, inplace=True)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:05:44.523596Z",
     "start_time": "2020-12-09T19:05:43.689868Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Colocar target_type\n",
    "for feature in categorical_cols:\n",
    "    if feature not in ['attack']:\n",
    "        apply_dummies(data_scaled, feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:05:46.127069Z",
     "start_time": "2020-12-09T19:05:46.108308Z"
    }
   },
   "outputs": [],
   "source": [
    "data_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:05:47.751609Z",
     "start_time": "2020-12-09T19:05:47.733649Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset = data_scaled\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:06:01.088004Z",
     "start_time": "2020-12-09T19:06:00.499513Z"
    }
   },
   "outputs": [],
   "source": [
    "#Separa os dados entre treino e teste\n",
    "train, test = np.split(dataset.sample(frac=1), [int(TRAIN_PERCENTAGE * len(dataset))])\n",
    "\n",
    "train_samples = train.drop(['attack'], axis=1)\n",
    "train_labels = to_categorical(train[['attack']].to_numpy(), num_classes=len(attack_values))\n",
    "\n",
    "test_samples = test.drop(['attack'], axis=1)\n",
    "test_labels = to_categorical(test[['attack']].to_numpy(), num_classes=len(attack_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:06:02.090731Z",
     "start_time": "2020-12-09T19:06:02.086974Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train_samples.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_samples.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelo da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:06:08.128403Z",
     "start_time": "2020-12-09T19:06:08.094826Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = (train_samples.shape[1],)\n",
    "\n",
    "# Dense(15, activation=ACTIVATION_FN),\n",
    "# Criação do modelo\n",
    "model = Sequential([\n",
    "    Dense(50, input_shape=input_shape, activation=ACTIVATION_FN),\n",
    "    Dense(50, activation=ACTIVATION_FN),\n",
    "    Dense(50, activation=ACTIVATION_FN),\n",
    "    Dense(50, activation=ACTIVATION_FN),\n",
    "    Dense(50, activation=ACTIVATION_FN),\n",
    "    Dense(50, activation=ACTIVATION_FN),\n",
    "    Dense(50, activation=ACTIVATION_FN),\n",
    "    Dense(50, activation=ACTIVATION_FN),\n",
    "    Dense(50, activation=ACTIVATION_FN),\n",
    "    Dense(50, activation=ACTIVATION_FN),\n",
    "    Dense(len(attack_values), activation='softmax'),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:06:09.302007Z",
     "start_time": "2020-12-09T19:06:09.297387Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:06:13.328612Z",
     "start_time": "2020-12-09T19:06:13.318262Z"
    }
   },
   "outputs": [],
   "source": [
    "sgd = optimizers.SGD(lr=LEARNING_RATE)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=sgd,\n",
    "    loss='categorical_crossentropy', \n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "# categorical_crossentropy\n",
    "# mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treino da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:07:16.036014Z",
     "start_time": "2020-12-09T19:06:15.416210Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# Treinamento do modelo\n",
    "history = model.fit(\n",
    "    x=train_samples, \n",
    "    y=train_labels, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    epochs=EPOCHS,\n",
    "    shuffle=SHUFFLE, #Mistura os dados\n",
    "    verbose=VERBOSE,\n",
    "    validation_split=VALIDATION_PERCENTAGE #Porcentagem dos dados de treino que serão usadas para validação\n",
    ")\n",
    "\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teste da rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:07:18.618675Z",
     "start_time": "2020-12-09T19:07:16.932191Z"
    }
   },
   "outputs": [],
   "source": [
    "# Teste do modelo\n",
    "h2 = model.evaluate(\n",
    "    x=test_samples,\n",
    "    y=test_labels,\n",
    "    verbose=VERBOSE,\n",
    ")\n",
    "# plot_model(model, to_file='model.png' ,show_shapes=True, show_layer_names=True, expand_nested=True, dpi=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impressão dos resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T19:07:19.740900Z",
     "start_time": "2020-12-09T19:07:19.482998Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot_model(model, to_file='model.png')\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "print(model.metrics_names)\n",
    "print(h2)\n",
    "\n",
    "print({\n",
    "\"CLEAN_DATASET\":CLEAN_DATASET,\n",
    "\"DATASET_COMPLETO\":DATASET_COMPLETO,\n",
    "\"CORRCOEF_THRESHOLD\":CORRCOEF_THRESHOLD,\n",
    "\"BATCH_SIZE\":BATCH_SIZE,\n",
    "\"EPOCHS\":EPOCHS,\n",
    "\"SHUFFLE\":SHUFFLE,\n",
    "\"VERBOSE\":VERBOSE,\n",
    "\"VALIDATION_SPLIT\":VALIDATION_PERCENTAGE,\n",
    "\"LEARNING_RATE\":LEARNING_RATE,\n",
    "\"ACTIVATION_FN\":ACTIVATION_FN,\n",
    "\"TEMPO\": end_time-start_time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-09T18:30:25.151237Z",
     "start_time": "2020-12-09T18:30:25.148362Z"
    }
   },
   "outputs": [],
   "source": [
    "# np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "# from keras import backend as K\n",
    "\n",
    "# with a Sequential model\n",
    "# get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "#                                   [model.layers[3].output])\n",
    "# print(get_3rd_layer_output)\n",
    "\n",
    "# print(model.layers[0].input)\n",
    "# print(model.layers[0].output)\n",
    "\n",
    "# print(model.layers[1].input)\n",
    "# print(model.layers[1].output)\n",
    "\n",
    "# print(model.layers[2].input)\n",
    "# print(model.layers[2].output)\n",
    "\n",
    "# print(model.layers[3].input)\n",
    "# print(model.layers[3].output)\n",
    "\n",
    "# from keras import backend as K\n",
    "\n",
    "# input1 = model.input # input placeholder\n",
    "\n",
    "# output1 = [layer.output for layer in model.layers]# all layer outputs\n",
    "\n",
    "# fun = K.function([input1, K.learning_phase()],output1)# evaluation function\n",
    "\n",
    "# # Testing\n",
    "\n",
    "# t = np.random.random((41,))[np.newaxis,...]\n",
    "\n",
    "# t = np.array([[0,1,19,9,181,5450,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,8,8,0.00,0.00,0.00,0.00,1.00,0.00,0.00,9,9,1.00,0.00,0.11,0.00,0.00,0.00,0.00,0.00]])\n",
    "\n",
    "# layer_outputs = fun([t, 1])\n",
    "\n",
    "\n",
    "\n",
    "# print(layer_outputs[0]) #printing the outputs of layers\n",
    "# print(layer_outputs[1]) #printing the outputs of layers\n",
    "# print(layer_outputs[2]) #printing the outputs of layers\n",
    "# print(layer_outputs[3]) #printing the outputs of layers"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

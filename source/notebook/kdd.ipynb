{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as cp\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(x, y, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(x), y))\n",
    "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def input_fn_test(x, y, batch_size):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(x), y))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"duration\", \"protocol_type\", \"service\", \"flag\", \"src_bytes\", \"dst_bytes\", \"land\", \"wrong_fragment\", \"urgent\", \"hot\", \"num_failed_logins\", \"logged_in\",\n",
    "                \"num_compromised\", \"root_shell\", \"su_attempted\", \"num_root\", \"num_file_creations\", \"num_shells\", \"num_access_files\", \"num_outbound_cmds\", \"is_host_login\",\n",
    "                \"is_guest_login\", \"count\", \"srv_count\", \"serror_rate\", \"srv_serror_rate\", \"rerror_rate\", \"srv_rerror_rate\", \"same_srv_rate\", \"diff_srv_rate\", \"srv_diff_host_rate\",\n",
    "                \"dst_host_count\", \"dst_host_srv_count\", \"dst_host_same_srv_rate\", \"dst_host_diff_srv_rate\", \"dst_host_same_src_port_rate\", \"dst_host_srv_diff_host_rate\",\n",
    "                \"dst_host_serror_rate\", \"dst_host_srv_serror_rate\", \"dst_host_rerror_rate\", \"dst_host_srv_rerror_rate\", \"attack\"]\n",
    "\n",
    "dataset = pd.read_csv('../../dataset/kddcup.data_10_percent_corrected', header=None, names=column_names)\n",
    "\n",
    "protocol_type = {\"icmp\": 0, \"tcp\": 1, \"udp\": 2}\n",
    "service = {\"auth\": 0, \"bgp\": 1, \"courier\": 2, \"csnet_ns\": 3, \"ctf\": 4, \"daytime\": 5, \"discard\": 6, \"domain\": 7, \"domain_u\": 8, \"echo\": 9, \"eco_i\": 10, \"ecr_i\": 11, \"efs\": 12,\n",
    "           \"exec\": 13, \"finger\": 14, \"ftp\": 15, \"ftp_data\": 16, \"gopher\": 17, \"hostnames\": 18, \"http\": 19, \"http_443\": 20, \"imap4\": 21, \"IRC\": 22, \"iso_tsap\": 23, \"klogin\": 24,\n",
    "           \"kshell\": 25, \"ldap\": 26, \"link\": 27, \"login\": 28, \"mtp\": 29, \"name\": 30, \"netbios_dgm\": 31, \"netbios_ns\": 32, \"netbios_ssn\": 33, \"netstat\": 34, \"nnsp\": 35, \"nntp\": 36,\n",
    "           \"ntp_u\": 37, \"other\": 38, \"pm_dump\": 39, \"pop_2\": 40, \"pop_3\": 41, \"printer\": 42, \"private\": 43, \"red_i\": 44, \"remote_job\": 45, \"rje\": 46, \"shell\": 47, \"smtp\": 48,\n",
    "           \"sql_net\": 49, \"ssh\": 50, \"sunrpc\": 51, \"supdup\": 52, \"systat\": 53, \"telnet\": 54, \"tftp_u\": 55, \"time\": 56, \"tim_i\": 57, \"urh_i\": 58, \"urp_i\": 59, \"uucp\": 60,\n",
    "           \"uucp_path\": 61, \"vmnet\": 62, \"whois\": 63, \"X11\": 64, \"Z39_50\": 65}\n",
    "flag = {\"OTH\": 0, \"REJ\": 1, \"RSTO\": 2, \"RSTOS0\": 3, \"RSTR\": 4, \"S0\": 5, \"S1\": 6, \"S2\": 7, \"S3\": 8, \"SF\": 9, \"SH\": 10}\n",
    "attack = {\"back.\": 0, \"buffer_overflow.\": 1, \"ftp_write.\": 2, \"guess_passwd.\": 3, \"imap.\": 4, \"ipsweep.\": 5, \"land.\": 6, \"loadmodule.\": 7, \"multihop.\": 8, \"neptune.\": 9,\n",
    "          \"nmap.\": 10, \"normal.\": 11, \"perl.\": 12, \"phf.\": 13, \"pod.\": 14, \"portsweep.\": 15, \"rootkit.\": 16, \"satan.\": 17, \"smurf.\": 18, \"spy.\": 19, \"teardrop.\": 20,\n",
    "          \"warezclient.\": 21, \"warezmaster.\": 22}\n",
    "\n",
    "#Troca os valores de string para número\n",
    "dataset = dataset.replace({\"protocol_type\": protocol_type, \"service\": service, \"flag\": flag, \"attack\": attack})\n",
    "\n",
    "#Coloca todas em columas de feature em x e a de resultado em y\n",
    "x, y = dataset, dataset.pop(\"attack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\python36\\lib\\site-packages\\numpy\\lib\\function_base.py:3183: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "c:\\python\\python36\\lib\\site-packages\\numpy\\lib\\function_base.py:3184: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "included_features = column_names\n",
    "included_features.remove(\"attack\")\n",
    "\n",
    "CORRCOEF_THRESHOLD = 0.5\n",
    "\n",
    "i = 0\n",
    "j = 1\n",
    "while i < len(included_features):\n",
    "    col1 = dataset[column_names[i]]\n",
    "\n",
    "    while j < len(included_features):\n",
    "        col2 = dataset[column_names[j]]\n",
    "        corrcoef = cp.corrcoef(col1, col2)\n",
    "\n",
    "        if abs(corrcoef[0][1]) > CORRCOEF_THRESHOLD:\n",
    "            included_features.remove(included_features[j])\n",
    "        else:\n",
    "            j = j + 1\n",
    "\n",
    "    i = i + 1\n",
    "    j = i + 1\n",
    "\n",
    "for feature in included_features: #Por algum motivo o pop dentro do while não funcionava\n",
    "    x.pop(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\Everton\\AppData\\Local\\Temp\\tmpojm2ccpc\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\Everton\\\\AppData\\\\Local\\\\Temp\\\\tmpojm2ccpc', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x0000025E10935748>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "Treinando\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\Everton\\AppData\\Local\\Temp\\tmpojm2ccpc\\model.ckpt.\n",
      "INFO:tensorflow:loss = 1011.17926, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 100 into C:\\Users\\Everton\\AppData\\Local\\Temp\\tmpojm2ccpc\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 4.887569e-06.\n",
      "Testando\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-06-00:06:17\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Everton\\AppData\\Local\\Temp\\tmpojm2ccpc\\model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-06-00:06:18\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.5573054, average_loss = 58.870815, global_step = 100, loss = 7534.5493\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: C:\\Users\\Everton\\AppData\\Local\\Temp\\tmpojm2ccpc\\model.ckpt-100\n",
      "Acc: 0.5573053956031799\n"
     ]
    }
   ],
   "source": [
    "n_train = math.ceil(len(x.index)*0.9)\n",
    "n_test = len(x.index) - n_train\n",
    "\n",
    "x_train = x[:n_train]\n",
    "y_train = y[:n_train]\n",
    "\n",
    "x_test = x[n_train:n_train+n_test]\n",
    "y_test = y[n_train:n_train+n_test]\n",
    "\n",
    "#x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "\n",
    "NUM_STEPS = 10000\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "feature_columns = []\n",
    "for feature in x_train.keys():\n",
    "    feature_columns.append(tf.feature_column.numeric_column(key=feature))\n",
    "\n",
    "hidden_units=[1000]    \n",
    "    \n",
    "shallow = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=hidden_units, #1 hidden layer com 1000 hidden units\n",
    "    n_classes=23) #Pode distinguir até 23 valores diferentes\n",
    "\n",
    "# Treino\n",
    "print(\"Treinando\")\n",
    "shallow.train(\n",
    "    input_fn=lambda:input_fn(x_train, y_train, BATCH_SIZE),\n",
    "    steps=NUM_STEPS)\n",
    "\n",
    "# Teste\n",
    "print(\"Testando\")\n",
    "eval_result = shallow.evaluate(\n",
    "    input_fn=lambda:input_fn_test(x_test, y_test, BATCH_SIZE))\n",
    "\n",
    "print(f'Acc: {eval_result[\"accuracy\"]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
